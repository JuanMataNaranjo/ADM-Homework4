{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:56013</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.50 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:56013' processes=4 threads=4, memory=8.50 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rational"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He feel like we need to justify why we have come up with the following has table:\n",
    "\n",
    "We started looking into different hash functions, all of them resulting in different issues:\n",
    "\n",
    "- Convert string into binary: We used the function ord() in python, but it was giving very bas results\n",
    "- Convert letters into integers using ascii and convert each individual integer into its binary: We found this also to be problematic since most strings (except the number 0) would start with 1's. It also gave a very un-evenly distributed probabilities between 0 and 1.\n",
    "\n",
    "We then finally decided to generate a binary value of 5 digits (32 possible combinations) and then also add the 4 remaining values using smaller binary values in order to keep the distribution uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_to_binary(integer, decimals=None):\n",
    "    binary = ''\n",
    "    i = integer\n",
    "    while i >= 1:\n",
    "        binary = str(int(i%2)) + binary\n",
    "        i = i/2\n",
    "    if decimals:\n",
    "        binary = '0'*(decimals-len(binary)) + binary\n",
    "    return binary if binary else '0'\n",
    "\n",
    "def string_to_binary(string):\n",
    "    \n",
    "    binary = ''\n",
    "    for letter in string:\n",
    "        binary = binary + hash_dictionary[letter]\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_binary_df(df, column='User_ID'):\n",
    "    \n",
    "    df[column] = df.User_ID.apply(lambda x: string_to_binary(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_dataframe = ddf.from_pandas(users_df, npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "users_df_binary = dask_dataframe.map_partitions(string_to_binary_df, meta=users_df).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844082e02a27ddee8d99ea1af94a2969</td>\n",
       "      <td>1000010001000000100000101110000000101010001001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff96d6665b5c59d3a70bb8f2ba4f10be</td>\n",
       "      <td>1111111110010110110101100110011001011011010111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b64a85884e2b159829331c19e05dbac9</td>\n",
       "      <td>1011011001001010100001011000100001001110001010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c8836719e84867c26ba2cfeb372c53d</td>\n",
       "      <td>0001110010001000001101100111000110011110100001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b66f73ffd9008d9c99159e164261df51</td>\n",
       "      <td>1011011001101111011100111111111111011001000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            User_ID  \\\n",
       "0  844082e02a27ddee8d99ea1af94a2969   \n",
       "1  ff96d6665b5c59d3a70bb8f2ba4f10be   \n",
       "2  b64a85884e2b159829331c19e05dbac9   \n",
       "3  1c8836719e84867c26ba2cfeb372c53d   \n",
       "4  b66f73ffd9008d9c99159e164261df51   \n",
       "\n",
       "                                              Binary  \n",
       "0  1000010001000000100000101110000000101010001001...  \n",
       "1  1111111110010110110101100110011001011011010111...  \n",
       "2  1011011001001010100001011000100001001110001010...  \n",
       "3  0001110010001000001101100111000110011110100001...  \n",
       "4  1011011001101111011100111111111111011001000000...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split binary values into categories (m) based on a new hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_binary(df, m=64, column='Binary', max_zeros_per_bucket={}):\n",
    "    \"\"\"\n",
    "    This function will take a df with binary values (binary values are the hashed unique user ids) \n",
    "    and splits them into a set of buckets (m). For each of these buckets the function will also compute \n",
    "    the maximum number of zero's at the end of each binary number. The function will then return this \n",
    "    list which will then be used to estimate the distinct count value\n",
    "    \n",
    "    df: Dataframe with a column of binary values\n",
    "    m: Number of buckets\n",
    "    \"\"\"    \n",
    "    len_buckets = int(np.log2(m))\n",
    "    #max_zeros_per_bucket = get_bucket_groups(m)\n",
    "\n",
    "    for index, user_id in df[[column]].iterrows():\n",
    "        group = user_id[0][:len_buckets]\n",
    "        num_final_zeros = len(user_id[0]) - len(user_id[0].rstrip('0'))\n",
    "        try:\n",
    "            max_zeros_per_bucket[group] = max(max_zeros_per_bucket[group], num_final_zeros)\n",
    "        except:\n",
    "            print(index)\n",
    "    \n",
    "    return max_zeros_per_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_groups(m=64):\n",
    "    \"\"\"\n",
    "    Function that will give us the initial binary values to bucket our hashed binary values\n",
    "    \"\"\"\n",
    "    buckets = {}\n",
    "    len_binary = int(np.log2(m))\n",
    "    for i in range(m):\n",
    "        bucket_binary = decimal_to_binary(i, decimals=len_binary)\n",
    "        buckets[bucket_binary] = 0\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha(m):\n",
    "    \"\"\"\n",
    "    Function to compute the alpha value used correct a systematic multiplicative bias\n",
    "    Instead of computing the integral we have taken the constant values from wikipedia\n",
    "    \"\"\"\n",
    "    \n",
    "    if m == 16:\n",
    "        alpha = 0.673\n",
    "    elif m == 32:\n",
    "        alpha = 0.697\n",
    "    elif m == 64:\n",
    "        alpha = 0.709\n",
    "    else:\n",
    "        alpha = 0.7213 / (1+ (1.079/m))\n",
    "    \n",
    "    return alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_per_bucket = split_binary(users_df_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperloglog_estimate(max_zeros):\n",
    "    \"\"\"\n",
    "    Returns the estimated hyperloglog estimate and its estimated error\n",
    "    \n",
    "    max_zeros: A list with all the max values over which the harmonic mean will be applied\n",
    "    \"\"\"\n",
    "    \n",
    "    max_zeros = np.array(max_zeros)\n",
    "    m = len(max_zeros)\n",
    "    \n",
    "    Z = float(2)**(-max_zeros)\n",
    "    Z = 1 / (np.sum(Z))\n",
    "    \n",
    "    estimate = compute_alpha(m) * m**2 * Z\n",
    "    \n",
    "    error = 1.04 / np.sqrt(m)\n",
    "    \n",
    "    return estimate, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiDict = {chr(i): i for i in range(97, 103)}\n",
    "list_values = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] + list(asciiDict.keys())\n",
    "list_binary = list(get_bucket_groups(16).keys())\n",
    "\n",
    "df_hash = pd.DataFrame(columns=['Original', 'Binary'])\n",
    "df_hash['Original'] = list_values\n",
    "df_hash['Binary'] = list_binary\n",
    "df_hash['# 0'] = [i.count('0') for i in list_binary]\n",
    "df_hash['# 1'] = [i.count('1') for i in list_binary]\n",
    "\n",
    "hash_dictionary = dict(zip(df_hash.Original, df_hash.Binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperloglog(path_df='data/hash.txt', num_substreams=64, hash_dict=hash_dictionary, chunksize=1000000):\n",
    "    \"\"\"\n",
    "    This function takes as input a txt file and estimates the length of unique values using the hyperloglog using a given\n",
    "    number of substreams (number of substreams over which the harmonic mean will be computed).\n",
    "    \n",
    "    It is also necesary to provide the used hashing table (maps hexadecimal values into binary).\n",
    "    \n",
    "    Assumptions:\n",
    "    - The unique values are in hexadecimal form\n",
    "    - Unique values are randomly and uniformly distributed\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # \n",
    "    max_zeros_per_bucket = get_bucket_groups(num_substreams)\n",
    "    \n",
    "    count = 0\n",
    "    for users_df in pd.read_csv(path_df, sep=\" \", header=None, chunksize=chunksize):\n",
    "        print(count)\n",
    "        print('============')\n",
    "        count+=1\n",
    "        users_df.columns = [\"User_ID\"]\n",
    "        \n",
    "        dask_dataframe = ddf.from_pandas(users_df, npartitions=20)\n",
    "        users_df_binary = dask_dataframe.map_partitions(string_to_binary_df, meta=users_df).compute()\n",
    "        \n",
    "        max_zeros_per_bucket = split_binary(users_df_binary, m=num_substreams, \n",
    "                                            column='User_ID', max_zeros_per_bucket=max_zeros_per_bucket)\n",
    "        \n",
    "    print('LOOP HAS FINISHED. WE WILL NOW COMPUTE THE ESTIMATED DISTINCT COUNT VALUE')\n",
    "    \n",
    "    return hyperloglog_estimate(list(max_zeros_per_bucket.values()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "============\n",
      "1\n",
      "============\n",
      "2\n",
      "============\n",
      "3\n",
      "============\n",
      "4\n",
      "============\n",
      "5\n",
      "============\n",
      "6\n",
      "============\n",
      "7\n",
      "============\n",
      "8\n",
      "============\n",
      "9\n",
      "============\n",
      "10\n",
      "============\n",
      "11\n",
      "============\n",
      "12\n",
      "============\n",
      "13\n",
      "============\n",
      "14\n",
      "============\n",
      "15\n",
      "============\n",
      "16\n",
      "============\n",
      "17\n",
      "============\n",
      "18\n",
      "============\n",
      "19\n",
      "============\n",
      "20\n",
      "============\n",
      "21\n",
      "============\n",
      "22\n",
      "============\n",
      "23\n",
      "============\n",
      "24\n",
      "============\n",
      "25\n",
      "============\n",
      "26\n",
      "============\n",
      "27\n",
      "============\n",
      "28\n",
      "============\n",
      "29\n",
      "============\n",
      "30\n",
      "============\n",
      "31\n",
      "============\n",
      "32\n",
      "============\n",
      "33\n",
      "============\n",
      "34\n",
      "============\n",
      "35\n",
      "============\n",
      "36\n",
      "============\n",
      "37\n",
      "============\n",
      "38\n",
      "============\n",
      "39\n",
      "============\n",
      "40\n",
      "============\n",
      "41\n",
      "============\n",
      "42\n",
      "============\n",
      "43\n",
      "============\n",
      "44\n",
      "============\n",
      "45\n",
      "============\n",
      "46\n",
      "============\n",
      "47\n",
      "============\n",
      "48\n",
      "============\n",
      "49\n",
      "============\n",
      "50\n",
      "============\n",
      "51\n",
      "============\n",
      "52\n",
      "============\n",
      "53\n",
      "============\n",
      "54\n",
      "============\n",
      "55\n",
      "============\n",
      "56\n",
      "============\n",
      "57\n",
      "============\n",
      "58\n",
      "============\n",
      "59\n",
      "============\n",
      "60\n",
      "============\n",
      "61\n",
      "============\n",
      "62\n",
      "============\n",
      "63\n",
      "============\n",
      "64\n",
      "============\n",
      "65\n",
      "============\n",
      "66\n",
      "============\n",
      "67\n",
      "============\n",
      "68\n",
      "============\n",
      "69\n",
      "============\n",
      "70\n",
      "============\n",
      "71\n",
      "============\n",
      "72\n",
      "============\n",
      "73\n",
      "============\n",
      "74\n",
      "============\n",
      "75\n",
      "============\n",
      "76\n",
      "============\n",
      "77\n",
      "============\n",
      "78\n",
      "============\n",
      "79\n",
      "============\n",
      "80\n",
      "============\n",
      "81\n",
      "============\n",
      "82\n",
      "============\n",
      "83\n",
      "============\n",
      "84\n",
      "============\n",
      "85\n",
      "============\n",
      "86\n",
      "============\n",
      "87\n",
      "============\n",
      "88\n",
      "============\n",
      "89\n",
      "============\n",
      "90\n",
      "============\n",
      "91\n",
      "============\n",
      "92\n",
      "============\n",
      "93\n",
      "============\n",
      "94\n",
      "============\n",
      "95\n",
      "============\n",
      "96\n",
      "============\n",
      "97\n",
      "============\n",
      "98\n",
      "============\n",
      "99\n",
      "============\n",
      "100\n",
      "============\n",
      "101\n",
      "============\n",
      "102\n",
      "============\n",
      "103\n",
      "============\n",
      "104\n",
      "============\n",
      "105\n",
      "============\n",
      "106\n",
      "============\n",
      "107\n",
      "============\n",
      "108\n",
      "============\n",
      "109\n",
      "============\n",
      "110\n",
      "============\n",
      "111\n",
      "============\n",
      "112\n",
      "============\n",
      "113\n",
      "============\n",
      "114\n",
      "============\n",
      "115\n",
      "============\n",
      "116\n",
      "============\n",
      "117\n",
      "============\n",
      "118\n",
      "============\n",
      "119\n",
      "============\n",
      "120\n",
      "============\n",
      "121\n",
      "============\n",
      "122\n",
      "============\n",
      "123\n",
      "============\n",
      "124\n",
      "============\n",
      "125\n",
      "============\n",
      "126\n",
      "============\n",
      "127\n",
      "============\n",
      "128\n",
      "============\n",
      "129\n",
      "============\n",
      "130\n",
      "============\n",
      "131\n",
      "============\n",
      "132\n",
      "============\n",
      "133\n",
      "============\n",
      "134\n",
      "============\n",
      "135\n",
      "============\n",
      "136\n",
      "============\n",
      "137\n",
      "============\n",
      "138\n",
      "============\n",
      "LOOP HAS FINISHED. WE WILL NOW COMPUTE THE ESTIMATED DISTINCT COUNT VALUE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(65092998.003772885, 0.13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperloglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65092998.003772885, 0.13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperloglog_estimate(list(max_zeros_per_bucket.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperloglog_test(df, num_substreams=64, hash_dict=hash_dictionary):\n",
    "    \"\"\"\n",
    "    This function takes as input a txt file and estimates the length of unique values using the hyperloglog using a given\n",
    "    number of substreams (number of substreams over which the harmonic mean will be computed).\n",
    "    \n",
    "    It is also necesary to provide the used hashing table (maps hexadecimal values into binary).\n",
    "    \n",
    "    Assumptions:\n",
    "    - The unique values are in hexadecimal form\n",
    "    - Unique values are randomly and uniformly distributed\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    max_zeros_per_bucket = get_bucket_groups(num_substreams)\n",
    "    \n",
    "    max_zeros_per_bucket = split_binary(users_df_binary, m=num_substreams, column='User_ID', max_zeros_per_bucket=max_zeros_per_bucket)\n",
    "\n",
    "    return hyperloglog_estimate(list(max_zeros_per_bucket.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "\n",
    "df = pd.read_csv('data/hash.txt', sep=\" \", header=None, nrows=n)\n",
    "df.columns=['User_ID']\n",
    "dask_dataframe = ddf.from_pandas(df, npartitions=20)\n",
    "users_df_binary = dask_dataframe.map_partitions(string_to_binary_df, meta=df).compute()\n",
    "\n",
    "x = hyperloglog_test(users_df_binary, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if E <= (2**32)/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143165576.53333333"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2**32)/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50262.114437117954"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000010001000000100000101110000000101010001001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111111110010110110101100110011001011011010111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011011001001010100001011000100001001110001010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001110010001000001101100111000110011110100001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1011011001101111011100111111111111011001000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1011110111110101010101010001010000001111101111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0101010100001001001001010000010111011100101011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1111110110001111011000001011101111010110000110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0100101011101010011000101100010001110111010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0010001010101110010101011000010101111010101001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 User_ID\n",
       "0      1000010001000000100000101110000000101010001001...\n",
       "1      1111111110010110110101100110011001011011010111...\n",
       "2      1011011001001010100001011000100001001110001010...\n",
       "3      0001110010001000001101100111000110011110100001...\n",
       "4      1011011001101111011100111111111111011001000000...\n",
       "...                                                  ...\n",
       "99995  1011110111110101010101010001010000001111101111...\n",
       "99996  0101010100001001001001010000010111011100101011...\n",
       "99997  1111110110001111011000001011101111010110000110...\n",
       "99998  0100101011101010011000101100010001110111010000...\n",
       "99999  0010001010101110010101011000010101111010101001...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_zeros_per_bucket.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>844082e02a27ddee8d99ea1af94a2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff96d6665b5c59d3a70bb8f2ba4f10be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b64a85884e2b159829331c19e05dbac9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c8836719e84867c26ba2cfeb372c53d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b66f73ffd9008d9c99159e164261df51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>bdf555140fbd464a1700dd3604fe73b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>55092505dcac086871b895e35ac1cc81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>fd8f60bbd61988ce78de240240bda5a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>4aea62c4774099e8bec57e80e59c74f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>22ae55857aa596a5e07cd8f2f1002749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                User_ID\n",
       "0      844082e02a27ddee8d99ea1af94a2969\n",
       "1      ff96d6665b5c59d3a70bb8f2ba4f10be\n",
       "2      b64a85884e2b159829331c19e05dbac9\n",
       "3      1c8836719e84867c26ba2cfeb372c53d\n",
       "4      b66f73ffd9008d9c99159e164261df51\n",
       "...                                 ...\n",
       "99995  bdf555140fbd464a1700dd3604fe73b1\n",
       "99996  55092505dcac086871b895e35ac1cc81\n",
       "99997  fd8f60bbd61988ce78de240240bda5a3\n",
       "99998  4aea62c4774099e8bec57e80e59c74f1\n",
       "99999  22ae55857aa596a5e07cd8f2f1002749\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_bucket_groups(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10110110010010101000010110001000010011100010101100010101100110000010100100110011000111000001100111100000010111011011101011001001'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df_binary.iloc[2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['1111'] = max(x['1111'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0000': 0,\n",
       " '0001': 0,\n",
       " '0010': 0,\n",
       " '0011': 0,\n",
       " '0100': 0,\n",
       " '0101': 0,\n",
       " '0110': 0,\n",
       " '0111': 0,\n",
       " '1000': 0,\n",
       " '1001': 0,\n",
       " '1010': 0,\n",
       " '1011': 0,\n",
       " '1100': 0,\n",
       " '1101': 0,\n",
       " '1110': 0,\n",
       " '1111': 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_science_general] *",
   "language": "python",
   "name": "conda-env-data_science_general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
